{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b41514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ca567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = \"llama3.2:3b\"\n",
    "llm = ChatOllama(model=model, base_url=\"http://localhost:11434\")\n",
    "print(llm.invoke(\"What is the capital of France?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\",\n",
    "                              base_url=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6137db",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"health_supplements\"\n",
    "vector_store= FAISS.load_local(db_name,embeddings,allow_dangerous_deserialization=True)\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 5})\n",
    "\n",
    "question = \"how to gain muscle mass?\"\n",
    "retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever=retriever, name=\"health_supplements\", description=\"Search and return information about the health supplements for workout and gym\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9810dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff11ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,Sequence,TypedDict,Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3403b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state)-> Literal[\"generate\",\"rewrite\"]:\n",
    "\n",
    "    class grade(BaseModel):\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes'or 'no'\")\n",
    "\n",
    "    llm_with_structured_output = llm.with_structured_output(grade)\n",
    "\n",
    "    prompt =PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question.\\n\n",
    "        Here is the retrieved document:\\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\",\"question\"],\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_with_structured_output\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\":docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "    \n",
    "    else:   \n",
    "\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba356f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "\n",
    "    \"\"\"\n",
    "    Invokes the agent to generate a response based on current stae.Given \n",
    "    the queston, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the AGENT response appended to messages.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    llm_with_tools = llm.bind_tools(tools, tool_choice = \"required\")\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb204d",
   "metadata": {},
   "source": [
    "### Rewrite Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "\n",
    "    Transforms the query  to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages)): The current state\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---Transform Query---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(content = f\"\"\"\\n\n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\ng\n",
    "    Here is the initial question:\n",
    "    \\n ------------\\n\n",
    "    {question}\n",
    "    \\n ------------\\n\n",
    "    Formulate an improved questions: \"\"\",\n",
    "\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(msg)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "\n",
    "    Transforms the query  to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages)): The current state\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "    docs = last_message.content\n",
    "\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    repsonse = rag_chain.invoke({\"question\": question, \"context\": docs})\n",
    "    return {\"messages\": [repsonse]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END,START,StateGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"agent\",agent)\n",
    "retriever = ToolNode([retriever_tool])\n",
    "graph_builder.add_node(\"retriever\",retriever)\n",
    "graph_builder.add_node(\"rewrite\",rewrite)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"agent\", \n",
    "    \n",
    "    tools_condition, \n",
    "    {\n",
    "         \"tools\":\"retriever\",\n",
    "         END: END\n",
    "    }\n",
    ")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"retriever\",\n",
    "    grade_documents)\n",
    "\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "graph_builder.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7597e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "query= {\"messages\": [HumanMessage(\"How to gain muscle mass?\")]}\n",
    "\n",
    "for output in graph.stream(query):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Output from node '{key}':\")\n",
    "        pprint(\"-----\")\n",
    "        pprint(value, indent=4, width = 120)\n",
    "\n",
    "    pprint(\"\\n-------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
